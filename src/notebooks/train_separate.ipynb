{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c92bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dylan-kmutt/ubpd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ad7c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.helper import get_train_test_pids\n",
    "\n",
    "train_v_pids, test_pids = get_train_test_pids(\"../../data/dataset/images/\", seed=42)\n",
    "all_pids = train_v_pids + test_pids\n",
    "len(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9c0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import random\n",
    "import math\n",
    "\n",
    "def split_train_and_test(pids: List[int], seed: int = 42) -> Tuple[List[int], List[int]]:\n",
    "    if not pids:\n",
    "        return [], []\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    unique = list(dict.fromkeys(pids))\n",
    "    n = len(unique)\n",
    "\n",
    "    # Reproducible shuffle\n",
    "    rng = random.Random(seed)\n",
    "    idxs = list(range(n))\n",
    "    rng.shuffle(idxs)\n",
    "    shuffled = [unique[i] for i in idxs]\n",
    "\n",
    "    # Compute test size (â‰ˆ15%); keep at least 1 test if possible, and at least 1 train\n",
    "    raw_test = int(round(n * 0.15))\n",
    "    if n >= 2:\n",
    "        test_size = max(1, min(raw_test, n - 1))\n",
    "    else:\n",
    "        test_size = 0  # only one item â†’ all train\n",
    "\n",
    "    test_ids = shuffled[:test_size]\n",
    "    train_ids = shuffled[test_size:]\n",
    "\n",
    "    return train_ids, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd470e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultrasound 1 PIDS: 35\n",
      "Ultrasound 2 PIDS: 50\n"
     ]
    }
   ],
   "source": [
    "ultrasound_1_pids = [i for i in range(7, 44) if i in all_pids]\n",
    "\n",
    "sub_1_ultrasound_2_pids = [i for i in range(47, 166) if i in all_pids]\n",
    "sub_2_ultrasound_2_pids = [i for i in range(1, 6) if i in all_pids]\n",
    "ultrasound_2_pids = sub_1_ultrasound_2_pids + sub_2_ultrasound_2_pids\n",
    "\n",
    "print(f\"Ultrasound 1 PIDS: {len(ultrasound_1_pids)}\")\n",
    "print(f\"Ultrasound 2 PIDS: {len(ultrasound_2_pids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44c5d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultrasound 1: train 30 pids, test 5 pids\n",
      "Ultrasound 2: train 42 pids, test 8 pids\n"
     ]
    }
   ],
   "source": [
    "u1_train_pids, u1_test_pids = split_train_and_test(ultrasound_1_pids)\n",
    "u2_train_pids, u2_test_pids = split_train_and_test(ultrasound_2_pids)\n",
    "\n",
    "print(f\"Ultrasound 1: train {len(u1_train_pids)} pids, test {len(u1_test_pids)} pids\")\n",
    "print(f\"Ultrasound 2: train {len(u2_train_pids)} pids, test {len(u2_test_pids)} pids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1545001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.helper import get_cv_pids\n",
    "\n",
    "u1_cv_pids = get_cv_pids(u1_train_pids, cv=5)\n",
    "u2_cv_pids = get_cv_pids(u2_train_pids, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4ca45",
   "metadata": {},
   "source": [
    "# **Ultrasound 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a05e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import UBPDataset\n",
    "from src.preprocessing import PairedTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec145d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (3013833174.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"- Augment: {variants[\"augment\"]}\")\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.train import Trainer\n",
    "from src.evaluate import Evaluator\n",
    "from src.helper import (\n",
    "    set_seed,\n",
    "    _build_model_factory,\n",
    "    str2bool,\n",
    "    _make_paired_transform,\n",
    "    get_train_test_pids,\n",
    "    get_cv_pids,\n",
    "    aggregate_fold_metrics,\n",
    ")\n",
    "\n",
    "def experiment(variants, seed=42):\n",
    "    # CV\n",
    "    all_histories = []\n",
    "    fold_overall_means = []\n",
    "    fold_results = []  # store per-fold evaluator outputs (dicts)\n",
    "\n",
    "    exp_id = random.randint(int(1e5), int(1e6) - 1)\n",
    "    model_name = variants[\"model\"]\n",
    "\n",
    "    set_seed(seed)\n",
    "    print(f\"\\nðŸš€ Beginning experiment #{exp_id}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    include_classes = variants.get(\"include_classes\")\n",
    "    class_names = {\n",
    "        1: \"dongmai (artery)\",\n",
    "        2: \"jingmai (vein)\",\n",
    "        3: \"jirouzuzhi (muscle)\",\n",
    "        4: \"shenjing (nerve)\",\n",
    "    }\n",
    "    print(\"Included classes:\")\n",
    "    for cid in include_classes:\n",
    "        print(f\"  {cid}: {class_names.get(cid, 'unknown')}\")\n",
    "    print(f\"\\n- Model: {model_name}\")\n",
    "    print(f\"- Augment: {variants['augment']}\")\n",
    "\n",
    "    include_classes = variants[\"include_classes\"]\n",
    "    n_inc = len(include_classes)\n",
    "    if n_inc == 1:\n",
    "        variants[\"loss\"] = \"bce\"\n",
    "        num_classes_for_model = 1  # single foreground channel\n",
    "        keep_original_indices = True  # irrelevant when binary\n",
    "    else:\n",
    "        variants[\"loss\"] = \"ce\"\n",
    "        num_classes_for_model = n_inc + 1  # background + selected classes only\n",
    "        keep_original_indices = False  # remap selected IDs to contiguous {0..K}\n",
    "    variants[\"num_classes\"] = num_classes_for_model\n",
    "\n",
    "    print(\n",
    "        f\"- Using loss='{variants['loss']}' with model num_classes={num_classes_for_model}\"\n",
    "    )\n",
    "    if not keep_original_indices:\n",
    "        print(\n",
    "            \"- Remapping labels to contiguous IDs: background=0, selected classes=1..K\"\n",
    "        )\n",
    "    print(f\"- Image size: {variants['image_size']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    paired_train_tf = PairedTransform(size=variants[\"image_size\"], aug=variants[\"augment\"])\n",
    "    paired_test_tf = PairedTransform(size=variants[\"image_size\"], aug=False)\n",
    "    test_dataset = UBPDataset(\n",
    "        p_ids=u1_test_pids,\n",
    "        include_classes=include_classes,\n",
    "        image_dir=\"../../data/dataset/images\",\n",
    "        json_dir=\"../../data/dataset/labels/json_train\",\n",
    "        joint_transform=paired_test_tf,\n",
    "        keep_original_indices=True,\n",
    "    )\n",
    "\n",
    "    print(\"Test landmarks stat: \")\n",
    "    test_dataset.print_stats()\n",
    "    len(test_dataset)\n",
    "\n",
    "    for fold in range(1, len(u1_cv_pids)+1):\n",
    "        train_pids, val_pids = u1_cv_pids[fold-1]\n",
    "\n",
    "        print(f\"\\nðŸ“‚ Fold {fold}/{len(u1_cv_pids)}\")\n",
    "        print(f\"  Train patient IDs: {train_pids}\")\n",
    "        print(f\"  Val   patient IDs: {val_pids}\\n\")\n",
    "\n",
    "        train_dataset = UBPDataset(\n",
    "            p_ids=train_pids,\n",
    "            include_classes=include_classes,\n",
    "            image_dir=\"../../data/dataset/images\",\n",
    "            json_dir=\"../../data/dataset/labels/json_train\",\n",
    "            joint_transform=paired_train_tf,\n",
    "            keep_original_indices=keep_original_indices,  # <--- important\n",
    "        )\n",
    "\n",
    "        val_dataset = UBPDataset(\n",
    "            p_ids=val_pids,\n",
    "            include_classes=include_classes,\n",
    "            image_dir=\"../../data/dataset/images\",\n",
    "            json_dir=\"../../data/dataset/labels/json_train\",\n",
    "            joint_transform=paired_test_tf,\n",
    "            keep_original_indices=keep_original_indices,  # <--- important\n",
    "        )\n",
    "\n",
    "        print(\"Train landmarks stat: \")\n",
    "        train_dataset.print_stats()\n",
    "        print()\n",
    "        print(\"Validation landmarks stat:\")\n",
    "        val_dataset.print_stats()\n",
    "        val_dataset.visualize_image_transform(0)\n",
    "\n",
    "        make_model = _build_model_factory(model_name)\n",
    "        model = make_model(num_classes=num_classes_for_model)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            exp_id=exp_id,\n",
    "            fold_num=fold,\n",
    "            model=model,\n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            arguments=variants,\n",
    "        )\n",
    "        history = trainer.train()\n",
    "        all_histories.append(history)\n",
    "\n",
    "        if history[\"val_loss\"]:\n",
    "            best_idx = int(np.argmin(history[\"val_loss\"]))\n",
    "            print(\n",
    "                f\"  âœ… Best @ epoch {best_idx+1}: val_loss={history['val_loss'][best_idx]:.4f} | val_dice={history['val_dice'][best_idx]:.4f}\"\n",
    "            )\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Evaluate one fold (you can move this after the loop to evaluate the final/best model instead)\n",
    "        evaluator = Evaluator(\n",
    "            trainer.model,\n",
    "            test_dataset,\n",
    "            num_classes=num_classes_for_model,\n",
    "            ignore_empty_classes=False,\n",
    "        )\n",
    "        res = evaluator.evaluate_dice_score(show_plot=True)\n",
    "        evaluator.visualize_ranked()\n",
    "                # collect overall mean dice for this fold if available\n",
    "        try:\n",
    "            overall_mean = res.get(\"overall\", {}).get(\"mean\", float(\"nan\"))\n",
    "        except Exception:\n",
    "            overall_mean = float(\"nan\")\n",
    "        fold_overall_means.append(\n",
    "            float(overall_mean) if overall_mean is not None else float(\"nan\")\n",
    "        )\n",
    "        fold_results.append(res)\n",
    "\n",
    "    overall_mean, overall_std, per_class_stats = aggregate_fold_metrics(fold_results)\n",
    "    if not np.isnan(overall_mean):\n",
    "        print(\n",
    "            f\"\\nðŸŽ¯ Average overall Dice across folds: {overall_mean:.4f} Â± {overall_std:.4f}  (n={len(fold_results)})\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No per-fold overall Dice scores collected.\")\n",
    "\n",
    "    # Print per-landmark (per-class) averages\n",
    "    if per_class_stats:\n",
    "        print(\"\\nðŸ“Œ Per-landmark average Dice across folds:\")\n",
    "        for cid in sorted(per_class_stats.keys()):\n",
    "            stats = per_class_stats[cid]\n",
    "            name = class_names.get(cid, f\"class_{cid}\")\n",
    "            print(\n",
    "                f\"  {cid}: {name:<20s} meanÂ±std: {stats['mean']:.4f} Â± {stats['std']:.4f}  (folds={stats['n_folds']})\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No per-class stats available to aggregate.\")\n",
    "\n",
    "    print(\"\\nâœ… Experiment complete across folds.\")\n",
    "    return {\n",
    "        \"histories\": all_histories,\n",
    "        \"test_dataset\": test_dataset,\n",
    "        \"fold_overall_means\": fold_overall_means,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda484e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m variants \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m }\n\u001b[0;32m---> 25\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m(variants, \u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "variants = {\n",
    "    \"model\": \"unet\",\n",
    "    \"cv\": 5,\n",
    "    \"include_classes\": [4],\n",
    "\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 16,\n",
    "    \"num_workers\": 2,\n",
    "    \"image_size\": 512,\n",
    "    \n",
    "    \"patience\": 20,\n",
    "    \"scheduler\": \"plateau\",\n",
    "    \"plateau_cooldown\": 10,\n",
    "    \n",
    "    \"half_precision\": True,\n",
    "    \"ignore_empty\": False,\n",
    "    \"augment\": True,\n",
    "    \"cuda\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"use_wandb\": False,\n",
    "    \"save_dir\": \"../../checkpoints\"\n",
    "}\n",
    "\n",
    "res = experiment(variants, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0126f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
