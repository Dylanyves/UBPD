{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d32186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/dylan-kmutt/ubpd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f811e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b54362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def get_model_paths(model_id):\n",
    "    model_paths = []\n",
    "    for path in os.listdir(\"../../checkpoints\"):\n",
    "        if str(model_id) in path:\n",
    "            model_paths.append(f\"../../checkpoints/{path}\")\n",
    "    model_paths = sorted(model_paths)\n",
    "    print(\"Models found: \")\n",
    "    for i in model_paths:\n",
    "        print(f\"-- {i}\")\n",
    "    return model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluate import Evaluator\n",
    "from src.helper import load_model, aggregate_fold_metrics\n",
    "from src.preprocessing import PairedTransform\n",
    "from src.dataset import UBPDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fed624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pids(seed, ultrasound):\n",
    "    if seed == 42:\n",
    "        if ultrasound == \"u1\":\n",
    "            p_ids = [16, 19, 12, 36, 41]\n",
    "        if ultrasound == \"u2\":\n",
    "            p_ids = [61, 77, 79, 50, 75, 94, 68, 96]\n",
    "        if ultrasound == \"combined\":\n",
    "            p_ids = [16, 19, 12, 36, 41, 61, 77, 79, 50, 75, 94, 68, 96]\n",
    "    elif seed == 94:\n",
    "        if ultrasound == \"u1\":\n",
    "            p_ids = [11, 35, 32, 9, 8]\n",
    "        if ultrasound == \"u2\":\n",
    "            p_ids = [50, 62, 98, 4, 81, 96, 70, 68]\n",
    "        if ultrasound == \"combined\":\n",
    "            p_ids = [11, 35, 32, 9, 8, 50, 62, 98, 4, 81, 96, 70, 68]\n",
    "    elif seed == 33:\n",
    "        if ultrasound == \"u1\":\n",
    "            p_ids = [38, 19, 10, 42, 8]\n",
    "        if ultrasound == \"u2\":\n",
    "            p_ids = [131, 53, 6, 47, 78, 49, 76, 64]\n",
    "        if ultrasound == \"combined\":\n",
    "            p_ids = [38, 19, 10, 42, 8, 131, 53, 6, 47, 78, 49, 76, 64]\n",
    "    return p_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate(variants):\n",
    "    # CV\n",
    "    print(f\"üöÄBegininng evaluating model id {variants['model_id']}\\n\")\n",
    "    fold_overall_means = []\n",
    "    fold_results = []  # store per-fold evaluator outputs (dicts)\n",
    "\n",
    "    include_classes = variants.get(\"include_classes\")\n",
    "    class_names = {\n",
    "        1: \"dongmai (artery)\",\n",
    "        2: \"jingmai (vein)\",\n",
    "        3: \"jirouzuzhi (muscle)\",\n",
    "        4: \"shenjing (nerve)\",\n",
    "    }\n",
    "    print(\"Included classes:\")\n",
    "    for cid in include_classes:\n",
    "        print(f\"  {cid}: {class_names.get(cid, 'unknown')}\")\n",
    "\n",
    "    include_classes = variants[\"include_classes\"]\n",
    "    n_inc = len(include_classes)\n",
    "    if n_inc == 1:\n",
    "        variants[\"loss\"] = \"bce\"\n",
    "        num_classes_for_model = 1  # single foreground channel\n",
    "    else:\n",
    "        variants[\"loss\"] = \"ce\"\n",
    "        num_classes_for_model = n_inc + 1  # background + selected classes only\n",
    "    variants[\"num_classes\"] = num_classes_for_model\n",
    "\n",
    "    p_ids = get_pids(variants[\"seed\"], variants[\"test_pids\"])\n",
    "\n",
    "    paired_test_tf = PairedTransform(size=variants[\"image_size\"], aug=False)\n",
    "    test_dataset = UBPDataset(\n",
    "        p_ids=p_ids,\n",
    "        include_classes=include_classes,\n",
    "        image_dir=\"../../data/dataset/images\",\n",
    "        json_dir=\"../../data/dataset/labels/json_train\",\n",
    "        joint_transform=paired_test_tf,\n",
    "        keep_original_indices=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nTest landmarks stat: \")\n",
    "    test_dataset.print_stats()\n",
    "    len(test_dataset)\n",
    "\n",
    "    dices = []\n",
    "\n",
    "    model_paths = get_model_paths(variants[\"model_id\"])\n",
    "    for model_path in model_paths:\n",
    "        print(f\"\\nEvaluating: {model_path} ------------------\")\n",
    "\n",
    "        model = load_model(\n",
    "            model_path,\n",
    "            model_name=variants[\"model_name\"],\n",
    "            in_channels=1,\n",
    "            num_classes=num_classes_for_model,\n",
    "            device=variants[\"device\"],\n",
    "        )\n",
    "\n",
    "        # Evaluate one fold (you can move this after the loop to evaluate the final/best model instead)\n",
    "        evaluator = Evaluator(\n",
    "            model,\n",
    "            test_dataset,\n",
    "            num_classes=num_classes_for_model,\n",
    "            ignore_empty_classes=False,\n",
    "        )\n",
    "        res = evaluator.evaluate_dice_score(show_plot=True)\n",
    "        evaluator.visualize_ranked()\n",
    "        dices.append(evaluator.test_scores)\n",
    "\n",
    "        try:\n",
    "            overall_mean = res.get(\"overall\", {}).get(\"mean\", float(\"nan\"))\n",
    "        except Exception:\n",
    "            overall_mean = float(\"nan\")\n",
    "        fold_overall_means.append(\n",
    "            float(overall_mean) if overall_mean is not None else float(\"nan\")\n",
    "        )\n",
    "        fold_results.append(res)\n",
    "\n",
    "    overall_mean, overall_std, per_class_stats = aggregate_fold_metrics(fold_results)\n",
    "    if not np.isnan(overall_mean):\n",
    "        print(\n",
    "            f\"\\nüéØ Average overall Dice across folds: {overall_mean:.4f} ¬± {overall_std:.4f}  (n={len(fold_results)})\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No per-fold overall Dice scores collected.\")\n",
    "\n",
    "    # Print per-landmark (per-class) averages\n",
    "    if per_class_stats:\n",
    "        print(\"\\nüìå Per-landmark average Dice across folds:\")\n",
    "        for cid in sorted(per_class_stats.keys()):\n",
    "            stats = per_class_stats[cid]\n",
    "            name = class_names.get(cid, f\"class_{cid}\")\n",
    "            print(\n",
    "                f\"  {cid}: {name:<20s} mean¬±std: {stats['mean']:.4f} ¬± {stats['std']:.4f}  (folds={stats['n_folds']})\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No per-class stats available to aggregate.\")\n",
    "\n",
    "    print(\"\\n‚úÖ Experiment complete across folds.\")\n",
    "    return {\n",
    "        \"evaluator\": evaluator,\n",
    "        \"test_dataset\": test_dataset,\n",
    "        \"fold_overall_means\": fold_overall_means,\n",
    "        \"fold_results\": fold_results,\n",
    "        \"dices\": dices,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33254a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "variants = {\n",
    "    \"include_classes\": [1, 2, 3, 4],\n",
    "    \"model_name\": \"unet\",\n",
    "    \"model_id\": 909994,\n",
    "    \"test_pids\": \"u1\",\n",
    "    \"image_size\": 512,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 94,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e946a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = result[\"evaluator\"]\n",
    "ev.visualize_single(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev.visualize_single(-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578d50f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
